<?xml version="1.0" encoding="UTF-8"?>
<resourceDoc><classDocs><classDoc><className>org.apache.hive.hcatalog.templeton.BusyException</className><commentText><![CDATA[Simple "we are busy, try again" exception.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.ExecService</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>runUnlimited</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.EnqueueBean</className><commentText><![CDATA[EnqueueBean - The results of a call that enqueues a Hadoop job.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.JarDelegator</className><commentText><![CDATA[Submit a job to the MapReduce queue.

 This is the backend of the mapreduce/jar web service.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.CatchallExceptionMapper</className><commentText><![CDATA[Map all exceptions to the Jersey response.  This lets us have nice
 results in the error body.]]></commentText><methodDocs><methodDoc><methodName>toResponse</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.NotAuthorizedException</className><commentText><![CDATA[Simple "user not found" type exception.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.SqoopDelegator</className><commentText><![CDATA[Submit a Sqoop job.

 This is the backend of the Sqoop web service.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.UgiFactory</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>getUgi</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.AppConfig</className><commentText><![CDATA[The configuration for Templeton.  This merges the normal Hadoop
 configuration with the Templeton specific variables.

 The Templeton configuration variables are described in
 templeton-default.xml

 The Templeton specific configuration is split into two layers

 1. webhcat-default.xml - All the configuration variables that
    Templeton needs.  These are the defaults that ship with the app
    and should only be changed be the app developers.

 2. webhcat-site.xml - The (possibly empty) configuration that the
    system administrator can set variables for their Hadoop cluster.

 The configuration files are loaded in this order with later files
 overriding earlier ones.

 To find the configuration files, we first attempt to load a file
 from the CLASSPATH and then look in the directory specified in the
 TEMPLETON_HOME environment variable.

 In addition the configuration files may access the special env
 variable env for all environment variables.  For example, the
 hadoop executable could be specified using:
<pre>
      ${env.HADOOP_PREFIX}/bin/hadoop
</pre>]]></commentText><methodDocs><methodDoc><methodName>getListJobsOrder</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>startCleanup</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getHadoopConfDir</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getTempletonDir</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getWebhcatConfDir</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>jettyConfiguration</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>libJars</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopQueueName</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>enableJobReconnectDefault</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>clusterHadoop</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>clusterHcat</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>clusterPython</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>pigPath</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>pigArchive</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hivePath</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hiveArchive</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>sqoopPath</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>sqoopArchive</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>sqoopHome</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>streamingJar</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>kerberosSecret</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>kerberosPrincipal</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>kerberosKeytab</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>controllerMRChildOpts</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>controllerAMChildOpts</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>mapperMemoryMb</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>amMemoryMb</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hiveProps</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>overrideJars</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>overrideJarsString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>zkCleanupInterval</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>zkMaxAge</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>zkHosts</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>zkSessionTimeout</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.AppConfig.JobsListOrder</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>values</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>valueOf</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.SecureProxySupport</className><commentText><![CDATA[Helper class to run jobs using Kerberos security.  Always safe to
 use these methods, it's a no-op if security is not enabled.]]></commentText><methodDocs><methodDoc><methodName>getTokenPath</methodName><commentText><![CDATA[The file where we store the auth token]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getHcatServiceStr</methodName><commentText><![CDATA[The token to pass to hcat.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>open</methodName><commentText><![CDATA[Create the delegation token.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>close</methodName><commentText><![CDATA[Cleanup]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addEnv</methodName><commentText><![CDATA[Add Hadoop env variables.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addArgs</methodName><commentText><![CDATA[Add hcat args.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.HcatException</className><commentText><![CDATA[Unable to run hcat on the job.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.CompleteDelegator</className><commentText><![CDATA[Complete a job.  This will run the callback if

 - the job is done
 - there is a callback
 - the callback has not yet been called

 There is a small chance for a race condition if two callers run
 this at the same time.  That should never happen.

 We use a Hadoop config var to notify this class on the completion
 of a job.  Hadoop will call us multiple times in the event of
 failure.  Even if the failure is that the client callback failed.

 See LauncherDelegator for the HADOOP_END_RETRY* vars that are set.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>doCallback</methodName><commentText><![CDATA[Call the callback url with the jobid to let them know it's
 finished.  If the url has the string $jobId in it, it will be
 replaced with the completed jobid.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.VersionDelegator</className><commentText><![CDATA[Find the version of Hive, Hadoop, or Pig that is being used in this
 interface.]]></commentText><methodDocs><methodDoc><methodName>getVersion</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.StreamingDelegator</className><commentText><![CDATA[Submit a streaming job to the MapReduce queue.  Really just a front
 end to the JarDelegator.

 This is the backend of the mapreduce/streaming web service.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.StatusDelegator</className><commentText><![CDATA[Fetch the status of a given job id in the queue. There are three sources of the info
 1. Query result from JobTracker
 2. JobState saved by TempletonControllerJob when monitoring the TempletonControllerJob
 3. TempletonControllerJob put a JobState for every job it launches, so child job can
    retrieve its parent job by its JobState
 
 Currently there is no permission restriction, any user can query any job]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getJobStatus</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>StringToJobID</methodName><commentText><![CDATA[A version of JobID.forName with our app specific error handling.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.JobCallable</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>setJobStateFailed</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setJobStateCompleted</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>call</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>execute</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>cleanup</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.JobCallable.JobState</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>values</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>valueOf</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TempletonDelegator</className><commentText><![CDATA[The helper class for all the Templeton delegator classes. A
 delegator will call the underlying Templeton service such as hcat
 or hive.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.Server</className><commentText><![CDATA[The Templeton Web API server.]]></commentText><methodDocs><methodDoc><methodName>status</methodName><commentText><![CDATA[Check the status of this server.  Always OK.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>requestFormats</methodName><commentText><![CDATA[Check the supported request formats of this server.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>version</methodName><commentText><![CDATA[Check the version(s) supported by this server.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopVersion</methodName><commentText><![CDATA[Get version of hadoop software being run by this WebHCat server]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hiveVersion</methodName><commentText><![CDATA[Get version of hive software being run by this WebHCat server]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>sqoopVersion</methodName><commentText><![CDATA[Get version of sqoop software being run by this WebHCat server]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>pigVersion</methodName><commentText><![CDATA[Get version of pig software being run by this WebHCat server]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>ddl</methodName><commentText><![CDATA[Execute an hcat ddl expression on the local box.  It is run
 as the authenticated user and rate limited.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listTables</methodName><commentText><![CDATA[List all the tables in an hcat database.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createTable</methodName><commentText><![CDATA[Create a new table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createTableLike</methodName><commentText><![CDATA[Create a new table like another table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descTable</methodName><commentText><![CDATA[Describe an hcat table.  This is normally a simple list of
 columns (using "desc table"), but the extended format will show
 more information (using "show table extended like").]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>dropTable</methodName><commentText><![CDATA[Drop an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>renameTable</methodName><commentText><![CDATA[Rename an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descOneTableProperty</methodName><commentText><![CDATA[Describe a single property on an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listTableProperties</methodName><commentText><![CDATA[List all the properties on an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addOneTableProperty</methodName><commentText><![CDATA[Add a single property on an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listPartitions</methodName><commentText><![CDATA[List all the partitions in an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descPartition</methodName><commentText><![CDATA[Describe a single partition in an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addOnePartition</methodName><commentText><![CDATA[Create a partition in an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>dropPartition</methodName><commentText><![CDATA[Drop a partition in an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listDatabases</methodName><commentText><![CDATA[List all databases, or those that match a pattern.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descDatabase</methodName><commentText><![CDATA[Describe a database]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createDatabase</methodName><commentText><![CDATA[Create a database]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>dropDatabase</methodName><commentText><![CDATA[Drop a database]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listColumns</methodName><commentText><![CDATA[List the columns in an hcat table.  Currently the same as
 describe table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descColumn</methodName><commentText><![CDATA[Describe a single column in an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addOneColumn</methodName><commentText><![CDATA[Create a column in an hcat table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>mapReduceStreaming</methodName><commentText><![CDATA[Run a MapReduce Streaming job.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>mapReduceJar</methodName><commentText><![CDATA[Run a MapReduce Jar job.
 Params correspond to the REST api params]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>pig</methodName><commentText><![CDATA[Run a Pig job.
 Params correspond to the REST api params.  If '-useHCatalog' is in the {@code pigArgs, usesHcatalog},
 is interpreted as true.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>sqoop</methodName><commentText><![CDATA[Run a Sqoop job.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hive</methodName><commentText><![CDATA[Run a Hive job.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>execute</paramName><commentText><![CDATA[SQL statement to run, equivalent to "-e" from hive command line]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>execute</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>srcFile</paramName><commentText><![CDATA[name of hive script file to run, equivalent to "-f" from hive
                   command line]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>file</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>hiveArgs</paramName><commentText><![CDATA[additional command line argument passed to the hive command line.
                   Please check https://cwiki.apache.org/Hive/languagemanual-cli.html
                   for detailed explanation of command line arguments]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>arg</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>otherFiles</paramName><commentText><![CDATA[additional files to be shipped to the launcher, such as the jars
                   used in "add jar" statement in hive script]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>files</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>defines</paramName><commentText><![CDATA[shortcut for command line arguments "--define"]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>define</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>statusdir</paramName><commentText><![CDATA[where the stderr/stdout of templeton controller job goes]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>statusdir</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>callback</paramName><commentText><![CDATA[URL which WebHCat will call when the hive job finishes]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>callback</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>enablelog</paramName><commentText><![CDATA[whether to collect mapreduce log into statusdir/logs]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>enablelog</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>enablejobreconnect</paramName><commentText><![CDATA[whether to reconnect to a running child job on templeton
                              controller job retry]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.FormParam</annotationTypeName><attributes><attribute><name>value</name><value>enablejobreconnect</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc></paramDocs></methodDoc><methodDoc><methodName>showJobId</methodName><commentText><![CDATA[Return the status of the jobid.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>deleteJobId</methodName><commentText><![CDATA[Kill a job in the queue.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>showJobList</methodName><commentText><![CDATA[Return all the known job ids for this user based on the optional filter conditions.
 <p>
 Example usages:
 1. curl -s 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan'
 Return all the Job IDs submitted by hsubramaniyan
 2. curl -s
 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan%26showall=true'
 Return all the Job IDs that are visible to hsubramaniyan
 3. curl -s
 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan%26jobid=job_201312091733_0003'
 Return all the Job IDs for hsubramaniyan after job_201312091733_0003.
 4. curl -s 'http://localhost:50111/templeton/v1/jobs?
 user.name=hsubramaniyan%26jobid=job_201312091733_0003%26numrecords=5'
 Return the first 5(atmost) Job IDs submitted by hsubramaniyan after job_201312091733_0003.
 5.  curl -s
 'http://localhost:50111/templeton/v1/jobs?user.name=hsubramaniyan%26numrecords=5'
 Return the first 5(atmost) Job IDs submitted by hsubramaniyan after sorting the Job ID list
 lexicographically.
 </p>
 <p>
 Supporting pagination using "jobid" and "numrecords" parameters:
 Step 1: Get the start "jobid" = job_xxx_000, "numrecords" = n
 Step 2: Issue a curl command by specifying the user-defined "numrecords" and "jobid"
 Step 3: If list obtained from Step 2 has size equal to "numrecords", retrieve the list's
 last record and get the Job Id of the last record as job_yyy_k, else quit.
 Step 4: set "jobid"=job_yyy_k and go to step 2.
 </p>]]></commentText><responseDoc><returnDoc>list of job items based on the filter conditions specified by the user.</returnDoc></responseDoc><paramDocs><paramDoc><paramName>fields</paramName><commentText><![CDATA[If "fields" set to "*", the request will return full details of the job.
 If "fields" is missing, will only return the job ID. Currently the value can only
 be "*", other values are not allowed and will throw exception.]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.QueryParam</annotationTypeName><attributes><attribute><name>value</name><value>fields</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>showall</paramName><commentText><![CDATA[If "showall" is set to "true", the request will return all jobs the user
 has permission to view, not only the jobs belonging to the user.]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.QueryParam</annotationTypeName><attributes><attribute><name>value</name><value>showall</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>jobid</paramName><commentText><![CDATA[If "jobid" is present, the records whose Job Id is lexicographically greater
 than "jobid" are only returned. For example, if "jobid" = "job_201312091733_0001",
 the jobs whose Job ID is greater than "job_201312091733_0001" are returned. The number of
 records returned depends on the value of "numrecords".]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.QueryParam</annotationTypeName><attributes><attribute><name>value</name><value>jobid</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc><paramDoc><paramName>numrecords</paramName><commentText><![CDATA[If the "jobid" and "numrecords" parameters are present, the top #numrecords
 records appearing after "jobid" will be returned after sorting the Job Id list
 lexicographically.
 If "jobid" parameter is missing and "numrecords" is present, the top #numrecords will
 be returned after lexicographically sorting the Job Id list. If "jobid" parameter is present
 and "numrecords" is missing, all the records whose Job Id is greater than "jobid" are returned.]]></commentText><annotationDocs><annotationDoc><annotationTypeName>javax.ws.rs.QueryParam</annotationTypeName><attributes><attribute><name>value</name><value>numrecords</value></attribute></attributes></annotationDoc></annotationDocs></paramDoc></paramDocs></methodDoc><methodDoc><methodName>completeJob</methodName><commentText><![CDATA[Notify on a completed job.  Called by JobTracker.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>verifyUser</methodName><commentText><![CDATA[Verify that we have a valid user.  Throw an exception if invalid.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>verifyParam</methodName><commentText><![CDATA[Verify that the parameter exists.  Throw an exception if invalid.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>verifyParam</methodName><commentText><![CDATA[Verify that the parameter exists.  Throw an exception if invalid.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>verifyDdlParam</methodName><commentText><![CDATA[Verify that the parameter exists and is a simple DDL identifier
 name.  Throw an exception if invalid.

 Bug: This needs to allow for quoted ddl identifiers.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>verifyPropertyParam</methodName><commentText><![CDATA[Verify that the parameter exists and is a valid property
 name.  Throw an exception if invalid.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getCompletedUrl</methodName><commentText><![CDATA[The callback url on this server when a task is completed.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.ExecBean</className><commentText><![CDATA[ExecBean - The results of an exec call.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.BadParam</className><commentText><![CDATA[Missing required or badly configured paramater.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.LauncherDelegator</className><commentText><![CDATA[The helper class for all the Templeton delegator classes that
 launch child jobs.]]></commentText><methodDocs><methodDoc><methodName>registerJob</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>enqueueController</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>enqueueJob</methodName><commentText><![CDATA[Enqueue the TempletonControllerJob directly calling doAs.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeLauncherArgs</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addCacheFiles</methodName><commentText><![CDATA[Add files to the Distributed Cache for the controller job.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeOverrideClasspath</methodName><commentText><![CDATA[Create the override classpath, which will be added to
 HADOOP_CLASSPATH at runtime by the controller job.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addDef</methodName><commentText><![CDATA[Add a Hadoop command line definition to args if the value is
 not null.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.LauncherDelegator.JobType</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>values</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>valueOf</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.JobItemBean</className><commentText><![CDATA[]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.HcatDelegator</className><commentText><![CDATA[Run hcat on the local server using the ExecService.  This is
 the backend of the ddl web service.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[Run the local hcat executable.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descDatabase</methodName><commentText><![CDATA[Return a json description of the database.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listDatabases</methodName><commentText><![CDATA[Return a json "show databases like".  This will return a list of
 databases.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createDatabase</methodName><commentText><![CDATA[Create a database with the given name]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>dropDatabase</methodName><commentText><![CDATA[Drop the given database]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createTable</methodName><commentText><![CDATA[Create a table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createTableLike</methodName><commentText><![CDATA[Create a table like another.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descTable</methodName><commentText><![CDATA[Return a json description of the table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listTables</methodName><commentText><![CDATA[Return a json "show table like".  This will return a list of
 tables.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descExtendedTable</methodName><commentText><![CDATA[Return a json "show table extended like" with extra info from "desc exteded"
 This will return table with exact name match.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>dropTable</methodName><commentText><![CDATA[Drop a table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>renameTable</methodName><commentText><![CDATA[Rename a table.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descTableProperty</methodName><commentText><![CDATA[Describe one table property.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listTableProperties</methodName><commentText><![CDATA[List the table properties.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addOneTableProperty</methodName><commentText><![CDATA[Add one table property.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listPartitions</methodName><commentText><![CDATA[Return a json description of the partitions.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descOnePartition</methodName><commentText><![CDATA[Return a json description of one partition.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addOnePartition</methodName><commentText><![CDATA[Add one partition.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>dropPartition</methodName><commentText><![CDATA[Drop a partition.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listColumns</methodName><commentText><![CDATA[Return a json description of the columns.  Same as
 describeTable.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>descOneColumn</methodName><commentText><![CDATA[Return a json description of one column.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addOneColumn</methodName><commentText><![CDATA[Add one column.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.MaxByteArrayOutputStream</className><commentText><![CDATA[An output stream that will only accept the first N bytes of data.]]></commentText><methodDocs><methodDoc><methodName>write</methodName><commentText><![CDATA[Writes the specified byte to this byte array output stream.
 Any bytes after the first maxBytes will be ignored.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>b</paramName><commentText><![CDATA[the byte to be written.]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>write</methodName><commentText><![CDATA[Writes <code>len</code> bytes from the specified byte array
 starting at offset <code>off</code> to this byte array output stream.
 Any bytes after the first maxBytes will be ignored.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>b</paramName><commentText><![CDATA[the data.]]></commentText></paramDoc><paramDoc><paramName>off</paramName><commentText><![CDATA[the start offset in the data.]]></commentText></paramDoc><paramDoc><paramName>len</paramName><commentText><![CDATA[the number of bytes to write.]]></commentText></paramDoc></paramDocs></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.ListDelegator</className><commentText><![CDATA[List jobs owned by a user.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>listJobs</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getJobStatus</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.CompleteBean</className><commentText><![CDATA[CompleteBean - The results of an CompleteDelegator run.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.ColumnDesc</className><commentText><![CDATA[A description of the column to create.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.GroupPermissionsDesc</className><commentText><![CDATA[The base create permissions for ddl objects.]]></commentText><methodDocs><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.WadlConfig</className><commentText><![CDATA[Simple class that incorporates javadoc information into the
 wadl produced by jersey.]]></commentText><methodDocs><methodDoc><methodName>configure</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.DatabaseDesc</className><commentText><![CDATA[A description of the database to create.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.DeleteDelegator</className><commentText><![CDATA[Delete a job]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc</className><commentText><![CDATA[A description of the table to create.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc.ClusteredByDesc</className><commentText><![CDATA[How to cluster the table.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc.ClusterSortOrderDesc</className><commentText><![CDATA[The clustered sort order.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc.SortDirectionDesc</className><commentText><![CDATA[Ther ASC or DESC sort order.]]></commentText><methodDocs><methodDoc><methodName>values</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>valueOf</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc.StorageFormatDesc</className><commentText><![CDATA[The storage format.]]></commentText><methodDocs><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc.RowFormatDesc</className><commentText><![CDATA[The Row Format.]]></commentText><methodDocs><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc.SerdeDesc</className><commentText><![CDATA[The SERDE Row Format.]]></commentText><methodDocs><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableDesc.StoredByDesc</className><commentText><![CDATA[How to store the table.]]></commentText><methodDocs><methodDoc><methodName>equals</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.QueueException</className><commentText><![CDATA[Unable to queue the job]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TooManyRequestsException</className><commentText><![CDATA[Raise this exception if web service is busy with existing requests and not able
 service new requests.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.CallbackFailedException</className><commentText><![CDATA[The callback failed when it tried to reach the callback URL.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.PigDelegator</className><commentText><![CDATA[Submit a Pig job.

 This is the backend of the pig web service.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.QueueStatusBean</className><commentText><![CDATA[QueueStatusBean - The results of an exec call.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TablePropertyDesc</className><commentText><![CDATA[A description of a table property.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.PartitionDesc</className><commentText><![CDATA[A description of the partition to create.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.SimpleWebException</className><commentText><![CDATA[Simple exception that will return a json error payload if thrown
 from a JAX web server.  We skip using WebApplicationException and
 instead map our own so that Jersey doesn't log our exceptions as
 error in the output log.  See SimpleExceptionMapper.]]></commentText><methodDocs><methodDoc><methodName>getResponse</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>buildMessage</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.Main</className><commentText><![CDATA[The main executable that starts up and runs the Server.]]></commentText><methodDocs><methodDoc><methodName>getAppConfigInstance</methodName><commentText><![CDATA[Retrieve the config singleton.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>init</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>loadConfig</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>usage</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>runServer</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeXSRFFilter</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeAuthFilter</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeFrameOptionFilter</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeJerseyConfig</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addRedirects</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>main</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.Main.XFrameOptionsFilter</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>init</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>doFilter</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>destroy</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.HiveDelegator</className><commentText><![CDATA[Submit a Hive job.

 This is the backend of the hive web service.]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.JobRequestExecutor</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>isThreadPoolEnabled</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>execute</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.JobRequestExecutor.JobRequestType</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>values</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>valueOf</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.SimpleExceptionMapper</className><commentText><![CDATA[Map our exceptions to the Jersey response.  This lets us have nice
 results in the error body.]]></commentText><methodDocs><methodDoc><methodName>toResponse</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.JsonBuilder</className><commentText><![CDATA[Helper class to build new json objects with new top level
 properties.  Only add non-null entries.]]></commentText><methodDocs><methodDoc><methodName>create</methodName><commentText><![CDATA[Create a new map object from the existing json.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>create</methodName><commentText><![CDATA[Create a new map object.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createError</methodName><commentText><![CDATA[Create a new map error object.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>put</methodName><commentText><![CDATA[Add a non-null value to the map.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>remove</methodName><commentText><![CDATA[Remove a value from the map.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getMap</methodName><commentText><![CDATA[Get the underlying map.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>build</methodName><commentText><![CDATA[Turn the map back to response object.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>buildJson</methodName><commentText><![CDATA[Turn the map back to json.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>buildResponse</methodName><commentText><![CDATA[Turn the map back to response object.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>buildResponse</methodName><commentText><![CDATA[Turn the map back to response object.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>isset</methodName><commentText><![CDATA[Is the object non-empty?]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>isError</methodName><commentText><![CDATA[Check if this is an error doc.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>jsonToMap</methodName><commentText><![CDATA[Convert a json string to a Map.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>mapToJson</methodName><commentText><![CDATA[Convert a map to a json string.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.ExecServiceImpl</className><commentText><![CDATA[Execute a local program.  This is a singleton service that will
 execute programs as non-privileged users on the local box.  See
 ExecService.run and ExecService.runUnlimited for details.]]></commentText><methodDocs><methodDoc><methodName>getInstance</methodName><commentText><![CDATA[Retrieve the singleton.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>run</methodName><commentText><![CDATA[Run the program synchronously as the given user. We rate limit
 the number of processes that can simultaneously created for
 this instance.]]></commentText><responseDoc><returnDoc>The result of the run.</returnDoc></responseDoc><paramDocs><paramDoc><paramName>program</paramName><commentText><![CDATA[The program to run]]></commentText></paramDoc><paramDoc><paramName>args</paramName><commentText><![CDATA[Arguments to pass to the program]]></commentText></paramDoc><paramDoc><paramName>env</paramName><commentText><![CDATA[Any extra environment variables to set]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>runUnlimited</methodName><commentText><![CDATA[Run the program synchronously as the given user.  Warning:
 CommandLine will trim the argument strings.]]></commentText><responseDoc><returnDoc>The result of the run.</returnDoc></responseDoc><paramDocs><paramDoc><paramName>program</paramName><commentText><![CDATA[The program to run.]]></commentText></paramDoc><paramDoc><paramName>args</paramName><commentText><![CDATA[Arguments to pass to the program]]></commentText></paramDoc><paramDoc><paramName>env</paramName><commentText><![CDATA[Any extra environment variables to set]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>execEnv</methodName><commentText><![CDATA[Build the environment used for all exec calls.]]></commentText><responseDoc><returnDoc>The environment variables.</returnDoc></responseDoc></methodDoc><methodDoc><methodName>validateProgram</methodName><commentText><![CDATA[Given a program name, lookup the fully qualified path.  Throws
 an exception if the program is missing or not authorized.]]></commentText><responseDoc><returnDoc>The path of the validated program.</returnDoc></responseDoc><paramDocs><paramDoc><paramName>path</paramName><commentText><![CDATA[The path of the program.]]></commentText></paramDoc></paramDocs></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.TableLikeDesc</className><commentText><![CDATA[A description of the table to create that's like another table.]]></commentText><methodDocs><methodDoc><methodName>toString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.NotFoundException</className><commentText><![CDATA[Simple not found exception.]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.ZooKeeperCleanup</className><commentText><![CDATA[This does periodic cleanup]]></commentText><methodDocs><methodDoc><methodName>getInstance</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>startInstance</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>run</methodName><commentText><![CDATA[Run the cleanup loop.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getChildList</methodName><commentText><![CDATA[Get the list of jobs from JobState]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>checkAndDelete</methodName><commentText><![CDATA[Check to see if a job is more than maxage old, and delete it if so.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>exit</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.JobStateTracker</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>create</methodName><commentText><![CDATA[Create the parent znode for this job state.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>delete</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getJobID</methodName><commentText><![CDATA[Get the jobid for this tracking node]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeTrackingZnode</methodName><commentText><![CDATA[Make a ZK path to a new tracking node]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeTrackingJobZnode</methodName><commentText><![CDATA[Make a ZK path to an existing tracking node]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getTrackingJobs</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.NullSplit</className><commentText><![CDATA[An empty splitter.]]></commentText><methodDocs><methodDoc><methodName>getLength</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getLocations</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>write</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>readFields</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.LogRetriever</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.HDFSStorage</className><commentText><![CDATA[HDFS implementation of templeton storage.

  This implementation assumes that all keys in key/value pairs are
  chosen such that they don't have any newlines in them.]]></commentText><methodDocs><methodDoc><methodName>startCleanup</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>saveField</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getField</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>delete</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getAllForType</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>openStorage</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>closeStorage</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getPath</methodName><commentText><![CDATA[Get the path to storage based on the type.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>type</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>getPath</methodName><commentText><![CDATA[Static method to get the path based on the type.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>type</paramName><commentText><![CDATA[]]></commentText></paramDoc><paramDoc><paramName>root</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.NullRecordReader</className><commentText><![CDATA[An empty record reader.]]></commentText><methodDocs><methodDoc><methodName>initialize</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>close</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getCurrentKey</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getCurrentValue</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getProgress</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>nextKeyValue</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.JobState</className><commentText><![CDATA[The persistent state of a job.  The state is stored in one of the
 supported storage systems.]]></commentText><methodDocs><methodDoc><methodName>delete</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getStorageInstance</methodName><commentText><![CDATA[Get an instance of the selected storage class.  Defaults to
 HDFS storage if none is specified.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getStorage</methodName><commentText><![CDATA[Get an open instance of the selected storage class.  Defaults
 to HDFS storage if none is specified.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>close</methodName><commentText><![CDATA[For storage methods that require a connection, this is a hint
 that it's time to close the connection.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getId</methodName><commentText><![CDATA[This job id.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getPercentComplete</methodName><commentText><![CDATA[The percent complete of a job]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setPercentComplete</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>addChild</methodName><commentText><![CDATA[Add a jobid to the list of children of this job.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>jobid</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>setParent</methodName><commentText><![CDATA[Set parent job of this job]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>id</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>getParent</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getChildren</methodName><commentText><![CDATA[Get a list of jobstates for jobs that are children of this job.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getExitValue</methodName><commentText><![CDATA[The system exit value of the job.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setExitValue</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getCreated</methodName><commentText><![CDATA[When this job was created.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setCreated</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getUser</methodName><commentText><![CDATA[The user who started this job.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setUser</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getUserArgs</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setUserArgs</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getCallback</methodName><commentText><![CDATA[The url callback]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setCallback</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getCompleteStatus</methodName><commentText><![CDATA[The status of a job once it is completed.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setCompleteStatus</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getNotifiedTime</methodName><commentText><![CDATA[The time when the callback was sent.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setNotifiedTime</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getLongField</methodName><commentText><![CDATA[Fetch an integer field from the store.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setField</methodName><commentText><![CDATA[Store a String field from the store.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getField</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>setLongField</methodName><commentText><![CDATA[Store a long field.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>name</paramName><commentText><![CDATA[]]></commentText></paramDoc><paramDoc><paramName>val</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>getJobs</methodName><commentText><![CDATA[Get an id for each currently existing job, which can be used to create
 a JobState object.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>conf</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.TempletonControllerJob</className><commentText><![CDATA[A Map Reduce job that will start another job.

 We have a single Mapper job that starts a child MR job.  The parent
 monitors the child child job and ends when the child job exits.  In
 addition, we

 - write out the parent job id so the caller can record it.
 - run a keep alive thread so the job doesn't end.
 - Optionally, store the stdout, stderr, and exit value of the child
   in hdfs files.

 A note on security.  When jobs are submitted through WebHCat that use HCatalog, it means that
 metastore access is required.  Hive queries, of course, need metastore access.  This in turn
 requires delegation token to be obtained for metastore in a <em>secure cluster</em>.  Since we
 can't usually parse the job to find out if it is using metastore, we require 'usehcatalog'
 parameter supplied in the REST call.  WebHcat takes care of cancelling the token when the job
 is complete.]]></commentText><methodDocs><methodDoc><methodName>getSubmittedId</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>run</methodName><commentText><![CDATA[Enqueue the job and print out the job id for later collection.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.SingleInputFormat</className><commentText><![CDATA[An empty InputFormat.]]></commentText><methodDocs><methodDoc><methodName>getSplits</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>createRecordReader</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.JobSubmissionConstants</className><commentText><![CDATA[]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.JobSubmissionConstants.PigConstants</className><commentText><![CDATA[constants needed for Pig job submission
 The string values here are what Pig expects to see in it's environment]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.JobSubmissionConstants.Sqoop</className><commentText><![CDATA[]]></commentText></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.TempletonUtils</className><commentText><![CDATA[General utility methods.]]></commentText><methodDocs><methodDoc><methodName>isset</methodName><commentText><![CDATA[Is the object non-empty?]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>isset</methodName><commentText><![CDATA[Is the object non-empty?]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>isset</methodName><commentText><![CDATA[Is the object non-empty?]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>isset</methodName><commentText><![CDATA[Is the object non-empty?]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>isset</methodName><commentText><![CDATA[Is the object non-empty?]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>extractPercentComplete</methodName><commentText><![CDATA[Extract the percent complete line from Pig or Jar jobs.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>extractChildJobId</methodName><commentText><![CDATA[Extract the job id from jar jobs.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>encodeArray</methodName><commentText><![CDATA[Take an array of strings and encode it into one string.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>encodeArray</methodName><commentText><![CDATA[Encode a List into a string.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>decodeArray</methodName><commentText><![CDATA[Take an encode strings and decode it into an array of strings.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopFsListAsArray</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopFsListAsString</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopFsFilename</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopFsListChildren</methodName><commentText><![CDATA[Returns all files (non-recursive) in {@code dirName}]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopFsIsMissing</methodName><commentText><![CDATA[]]></commentText><responseDoc><returnDoc>true iff we are sure the file is not there.</returnDoc></responseDoc></methodDoc><methodDoc><methodName>addUserHomeDirectoryIfApplicable</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopFsPath</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>fetchUrl</methodName><commentText><![CDATA[GET the given url.  Returns the number of bytes received.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>hadoopUserEnv</methodName><commentText><![CDATA[Set the environment variables to specify the hadoop user.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>unEscapeString</methodName><commentText><![CDATA[replaces all occurrences of "\," with ","; returns {@code s} if no modifications needed]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>findContainingJar</methodName><commentText><![CDATA[Find a jar that contains a class of the same name and which
 file name matches the given pattern.]]></commentText><responseDoc><returnDoc>a jar file that contains the class, or null</returnDoc></responseDoc><paramDocs><paramDoc><paramName>clazz</paramName><commentText><![CDATA[the class to find.]]></commentText></paramDoc><paramDoc><paramName>fileNamePattern</paramName><commentText><![CDATA[regex pattern that must match the jar full path]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>dumpPropMap</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>dumpPropMap</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.ZooKeeperStorage</className><commentText><![CDATA[A storage implementation based on storing everything in ZooKeeper.
 This keeps everything in a central location that is guaranteed
 to be available and accessible.

 Data is stored with each key/value pair being a node in ZooKeeper.]]></commentText><methodDocs><methodDoc><methodName>zkOpen</methodName><commentText><![CDATA[Open a ZooKeeper connection for the JobState.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>zkOpen</methodName><commentText><![CDATA[Open a ZooKeeper connection for the JobState.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>close</methodName><commentText><![CDATA[Close this ZK connection.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>startCleanup</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>create</methodName><commentText><![CDATA[Create a node in ZooKeeper]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getPath</methodName><commentText><![CDATA[Get the path based on the job type.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>type</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>getPaths</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeFieldZnode</methodName><commentText><![CDATA[Make a ZK path to the named field.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>makeZnode</methodName><commentText><![CDATA[Make a ZK path to job]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>saveField</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getField</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>delete</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getAllForType</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>openStorage</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>closeStorage</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.DelegationTokenCache</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>getStringFormTokenCache</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>getDelegationToken</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>removeDelegationToken</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.LaunchMapper</className><commentText><![CDATA[Note that this class is used in a different JVM than WebHCat server.  Thus it should not call 
 any classes not available on every node in the cluster (outside webhcat jar).
 TempletonControllerJob#run() calls Job.setJarByClass(LaunchMapper.class) which
 causes webhcat jar to be shipped to target node, but not it's transitive closure.
 Long term we need to clean up this separation and create a separate jar to ship so that the
 dependencies are clear.  (This used to be an inner class of TempletonControllerJob)]]></commentText><methodDocs><methodDoc><methodName>run</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.TempletonStorage</className><commentText><![CDATA[An interface to handle different Templeton storage methods, including
 ZooKeeper and HDFS.  Any storage scheme must be able to handle being
 run in an HDFS environment, where specific file systems and virtual
 machines may not be available.

 Storage is done individually in a hierarchy: type (the data type,
 as listed below), then the id (a given jobid, jobtrackingid, etc.),
 then the key/value pairs.  So an entry might look like:

 JOB
   jobid00035
     user -&gt; rachel
     datecreated -&gt; 2/5/12
     etc.

 Each field must be available to be fetched/changed individually.]]></commentText><methodDocs><methodDoc><methodName>startCleanup</methodName><commentText><![CDATA[Start the cleanup process for this storage type.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>config</paramName><commentText><![CDATA[]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>saveField</methodName><commentText><![CDATA[Save a single key/value pair for a specific job id.]]></commentText><responseDoc/><paramDocs><paramDoc><paramName>type</paramName><commentText><![CDATA[The data type (as listed above)]]></commentText></paramDoc><paramDoc><paramName>id</paramName><commentText><![CDATA[The String id of this data grouping (jobid, etc.)]]></commentText></paramDoc><paramDoc><paramName>key</paramName><commentText><![CDATA[The name of the field to save]]></commentText></paramDoc><paramDoc><paramName>val</paramName><commentText><![CDATA[The value of the field to save]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>getField</methodName><commentText><![CDATA[Get the value of one field for a given data type.  If the type
 is UNKNOWN, search for the id in all types.]]></commentText><responseDoc><returnDoc>The value of the field requested, or null if not
 found.</returnDoc></responseDoc><paramDocs><paramDoc><paramName>type</paramName><commentText><![CDATA[The data type (as listed above)]]></commentText></paramDoc><paramDoc><paramName>id</paramName><commentText><![CDATA[The String id of this data grouping (jobid, etc.)]]></commentText></paramDoc><paramDoc><paramName>key</paramName><commentText><![CDATA[The name of the field to retrieve]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>delete</methodName><commentText><![CDATA[Delete a data grouping (all data for a jobid, all tracking data
 for a job, etc.).  If the type is UNKNOWN, search for the id
 in all types.]]></commentText><responseDoc><returnDoc>True if successful, false if not, throws NotFoundException
 if the id wasn't found.</returnDoc></responseDoc><paramDocs><paramDoc><paramName>type</paramName><commentText><![CDATA[The data type (as listed above)]]></commentText></paramDoc><paramDoc><paramName>id</paramName><commentText><![CDATA[The String id of this data grouping (jobid, etc.)]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>getAllForType</methodName><commentText><![CDATA[Get the id of each data grouping of a given type in the storage
 system.]]></commentText><responseDoc><returnDoc>A list of ids.</returnDoc></responseDoc><paramDocs><paramDoc><paramName>type</paramName><commentText><![CDATA[The data type (as listed above)]]></commentText></paramDoc></paramDocs></methodDoc><methodDoc><methodName>openStorage</methodName><commentText><![CDATA[For storage methods that require a connection, this is a hint
 that it's time to open a connection.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>closeStorage</methodName><commentText><![CDATA[For storage methods that require a connection, this is a hint
 that it's time to close the connection.]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.TempletonStorage.Type</className><commentText><![CDATA[]]></commentText><methodDocs><methodDoc><methodName>values</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>valueOf</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc><classDoc><className>org.apache.hive.hcatalog.templeton.tool.HDFSCleanup</className><commentText><![CDATA[This does periodic cleanup]]></commentText><methodDocs><methodDoc><methodName>getInstance</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>startInstance</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>run</methodName><commentText><![CDATA[Run the cleanup loop.]]></commentText><responseDoc/></methodDoc><methodDoc><methodName>exit</methodName><commentText><![CDATA[]]></commentText><responseDoc/></methodDoc></methodDocs></classDoc></classDocs></resourceDoc>
